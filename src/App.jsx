import React, { useState, useRef, useEffect } from 'react';
import { useConversation } from '@elevenlabs/react';
import Header from './components/Header';
import FeedbackModal from './components/FeedbackModal';
import UserWizard from './components/UserWizard';
import { Button } from './components/ui/button';
import { generateInterviewFeedback, generateAudioAnalysis, listAvailableModels } from './services/gemini';
import { MessageSquare, StopCircle, Mic, MicOff, Phone, PhoneOff } from 'lucide-react';

function App() {
  const [showWizard, setShowWizard] = useState(true);
  const [userData, setUserData] = useState(null);
  const [showFeedbackModal, setShowFeedbackModal] = useState(false);
  const [feedbackContent, setFeedbackContent] = useState('');
  const [isRequestingFeedback, setIsRequestingFeedback] = useState(false);
  const [conversationMessages, setConversationMessages] = useState([]);
  const [microphoneError, setMicrophoneError] = useState(null);
  const [audioAnalysisContent, setAudioAnalysisContent] = useState('');
  const [audioRecordingError, setAudioRecordingError] = useState(null);

  // Track if we're currently starting a session to prevent double-starts
  const isStartingSession = useRef(false);
  const connectionTimestamp = useRef(null);

  // Audio recording references
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const recordedAudioBlobRef = useRef(null);

  // Environment variables
  const ELEVENLABS_AGENT_ID = import.meta.env.VITE_ELEVENLABS_AGENT_ID;
  const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY;

  // ElevenLabs Conversation Hook with extensive logging
  const conversation = useConversation({
    overrides: {
      agent: {
        language: "de", // German language
        firstMessage: userData
          ? `Guten Tag ${userData.user_name}! Sch√∂n, dass Sie da sind. Ich freue mich, dass Sie sich f√ºr die Position als ${userData.position} bei ${userData.company} bewerben. Erz√§hlen Sie mir doch bitte zun√§chst etwas √ºber sich selbst und warum Sie sich f√ºr diese Position interessieren.`
          : "Guten Tag! Sch√∂n, dass Sie da sind. Erz√§hlen Sie mir doch bitte zun√§chst etwas √ºber sich selbst.",
      },
    },
    onConnect: () => {
      const now = Date.now();
      const timeSinceStart = connectionTimestamp.current ? now - connectionTimestamp.current : 0;
      console.log('üü¢ [CONNECTED] ElevenLabs WebSocket connected');
      console.log(`   Time since start: ${timeSinceStart}ms`);
      console.log(`   Conversation status: ${conversation.status}`);
      console.log(`   Microphone muted: ${conversation.micMuted}`);
      isStartingSession.current = false;
    },
    onDisconnect: (event) => {
      const now = Date.now();
      const timeSinceStart = connectionTimestamp.current ? now - connectionTimestamp.current : 0;
      console.log('üî¥ [DISCONNECTED] ElevenLabs WebSocket disconnected');
      console.log(`   Time since start: ${timeSinceStart}ms`);
      console.log(`   Conversation status: ${conversation.status}`);
      console.log(`   Disconnect event:`, event);
      console.log(`   Close code:`, event?.code);
      console.log(`   Close reason:`, event?.reason);
      console.log(`   Was clean:`, event?.wasClean);
      isStartingSession.current = false;

      // Set user-friendly error message based on close code
      if (event?.code === 1002 || event?.code === 1003) {
        setMicrophoneError('Agent-Konfigurationsfehler: Bitte √ºberpr√ºfe die Agent-Einstellungen im ElevenLabs Dashboard.');
      } else if (event?.code === 1006) {
        setMicrophoneError('Verbindung unerwartet getrennt. M√∂glicherweise stimmt die Agent-Konfiguration nicht.');
      } else if (event?.reason) {
        setMicrophoneError(`Verbindung getrennt: ${event.reason}`);
      }
    },
    onMessage: (message) => {
      console.log('üí¨ [MESSAGE] Received:', {
        source: message.source,
        message: message.message,
        timestamp: new Date().toISOString()
      });
      // Store messages for transcript
      setConversationMessages(prev => [...prev, message]);
    },
    onError: (error) => {
      console.error('‚ùå [ERROR] Conversation error:', {
        error,
        errorType: error?.constructor?.name,
        errorMessage: error?.message,
        errorStack: error?.stack,
        conversationStatus: conversation.status,
        timestamp: new Date().toISOString()
      });
      isStartingSession.current = false;
      setMicrophoneError(error?.message || 'Unknown error occurred');
    },
    onModeChange: (mode) => {
      console.log('üîÑ [MODE_CHANGE] New mode:', mode);
    },
  });

  /**
   * Starts recording audio from the user's microphone
   */
  const startAudioRecording = async () => {
    console.log('üéôÔ∏è [AUDIO REC] Starting audio recording...');

    try {
      setAudioRecordingError(null); // Clear any previous errors

      // Request microphone access
      // Note: This might fail if ElevenLabs is already using the microphone
      // In that case, we'll fallback to no audio analysis
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      console.log('üéôÔ∏è [AUDIO REC] Microphone stream obtained');
      console.log('üéôÔ∏è [AUDIO REC] Audio tracks:', stream.getAudioTracks().length);

      // Create MediaRecorder
      const mimeType = MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : 'audio/mp4';
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType
      });

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      // Handle data available event
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log(`üéôÔ∏è [AUDIO REC] Audio chunk recorded: ${event.data.size} bytes (Total chunks: ${audioChunksRef.current.length})`);
        }
      };

      // Handle recording stop event
      mediaRecorder.onstop = () => {
        console.log('üéôÔ∏è [AUDIO REC] Recording stopped');
        console.log(`üéôÔ∏è [AUDIO REC] Total chunks collected: ${audioChunksRef.current.length}`);

        const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
        recordedAudioBlobRef.current = audioBlob;
        console.log(`üéôÔ∏è [AUDIO REC] Total audio size: ${audioBlob.size} bytes`);

        if (audioBlob.size === 0) {
          console.warn('‚ö†Ô∏è [AUDIO REC] Warning: Audio blob is empty! No audio was recorded.');
          setAudioRecordingError('Keine Audio-Daten aufgenommen');
        }

        // Stop all tracks
        stream.getTracks().forEach(track => {
          track.stop();
          console.log('üéôÔ∏è [AUDIO REC] Stopped track:', track.label);
        });
      };

      // Handle errors during recording
      mediaRecorder.onerror = (event) => {
        console.error('‚ùå [AUDIO REC] MediaRecorder error:', event.error);
        setAudioRecordingError(`Aufnahmefehler: ${event.error?.message || 'Unbekannter Fehler'}`);
      };

      // Start recording
      mediaRecorder.start(1000); // Collect data every 1 second
      console.log('‚úÖ [AUDIO REC] Recording started successfully');
      console.log(`üéôÔ∏è [AUDIO REC] Recording state: ${mediaRecorder.state}`);

    } catch (error) {
      console.error('‚ùå [AUDIO REC] Error starting audio recording:', error);
      console.error('‚ùå [AUDIO REC] Error name:', error.name);
      console.error('‚ùå [AUDIO REC] Error message:', error.message);

      // Set user-friendly error message
      if (error.name === 'NotAllowedError') {
        setAudioRecordingError('Mikrofon-Zugriff wurde verweigert');
      } else if (error.name === 'NotFoundError') {
        setAudioRecordingError('Kein Mikrofon gefunden');
      } else if (error.name === 'NotReadableError') {
        setAudioRecordingError('Mikrofon wird bereits verwendet (m√∂glicherweise durch ElevenLabs)');
      } else {
        setAudioRecordingError(`Aufnahmefehler: ${error.message}`);
      }
    }
  };

  /**
   * Stops recording audio
   */
  const stopAudioRecording = () => {
    console.log('üõë [AUDIO REC] Stopping audio recording...');

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
      console.log('‚úÖ [AUDIO REC] Recording stopped successfully');
    } else {
      console.log('‚ö†Ô∏è [AUDIO REC] No active recording to stop');
    }
  };

  /**
   * Handles the end of interview and generates feedback
   */
  const handleEndInterview = async () => {
    // Stop audio recording first
    stopAudioRecording();

    // End the conversation
    if (conversation.status === 'connected') {
      await conversation.endSession();
    }

    setIsRequestingFeedback(true);
    setShowFeedbackModal(true);
    setFeedbackContent(''); // Clear previous feedback
    setAudioAnalysisContent(''); // Clear previous audio analysis

    try {
      // Build transcript from collected messages
      let transcript = '';
      if (conversationMessages.length > 0) {
        transcript = conversationMessages
          .map(msg => {
            const role = msg.source === 'ai' ? 'Herr M√ºller' : 'Bewerber';
            return `${role}: ${msg.message}`;
          })
          .join('\n\n');
      }

      // Fallback to mock transcript if no messages collected
      if (!transcript || transcript.trim().length === 0) {
        transcript = `
Herr M√ºller: Guten Tag! Sch√∂n, dass Sie da sind. Erz√§hlen Sie mir doch bitte zun√§chst etwas √ºber sich selbst.

Bewerber: [Ihre Antworten wurden hier aufgezeichnet]

Herr M√ºller: Das klingt interessant. Warum haben Sie sich f√ºr eine Ausbildung zum Mechatroniker bei BMW entschieden?

Bewerber: [Ihre Antworten wurden hier aufgezeichnet]

Herr M√ºller: K√∂nnen Sie mir von einer Situation erz√§hlen, in der Sie ein technisches Problem gel√∂st haben?

Bewerber: [Ihre Antworten wurden hier aufgezeichnet]
        `.trim();
      }

      // Generate both text feedback and audio analysis in parallel
      const feedbackPromise = generateInterviewFeedback(transcript, GEMINI_API_KEY);

      let audioAnalysisPromise = Promise.resolve(null);
      if (recordedAudioBlobRef.current && recordedAudioBlobRef.current.size > 0) {
        console.log('üéôÔ∏è [FEEDBACK] Analyzing recorded audio...');
        console.log(`üéôÔ∏è [FEEDBACK] Audio blob size: ${recordedAudioBlobRef.current.size} bytes`);
        audioAnalysisPromise = generateAudioAnalysis(recordedAudioBlobRef.current, GEMINI_API_KEY)
          .catch(error => {
            console.error('‚ùå [FEEDBACK] Audio analysis failed:', error);
            // Return a structured error message that will be displayed in the UI
            return JSON.stringify({
              summary: "Die Audio-Analyse konnte leider nicht durchgef√ºhrt werden.",
              error: true,
              errorMessage: error.message
            });
          });
      } else {
        console.warn('‚ö†Ô∏è [FEEDBACK] No audio recorded, skipping audio analysis');
        console.warn(`‚ö†Ô∏è [FEEDBACK] Audio blob size: ${recordedAudioBlobRef.current?.size || 0} bytes`);
        console.warn(`‚ö†Ô∏è [FEEDBACK] Audio recording error: ${audioRecordingError || 'None'}`);

        // Provide a message explaining why audio analysis is not available
        const reason = audioRecordingError || 'Es wurde kein Audio aufgenommen';
        audioAnalysisPromise = Promise.resolve(JSON.stringify({
          summary: `Audio-Analyse nicht verf√ºgbar: ${reason}`,
          error: true,
          errorMessage: reason
        }));
      }

      // Wait for both to complete
      const [feedback, audioAnalysis] = await Promise.all([feedbackPromise, audioAnalysisPromise]);

      setFeedbackContent(feedback);
      if (audioAnalysis) {
        console.log('üìä [FEEDBACK] Audio analysis result received');
        console.log(`üìä [FEEDBACK] Audio analysis length: ${audioAnalysis.length} characters`);
        setAudioAnalysisContent(audioAnalysis);
      } else {
        console.log('‚ö†Ô∏è [FEEDBACK] No audio analysis available');
      }
    } catch (error) {
      console.error('Error generating feedback:', error);
      setFeedbackContent(
        `Entschuldigung, es gab einen Fehler bei der Feedback-Generierung:\n\n${error.message}\n\nBitte stelle sicher, dass der GEMINI_API_KEY korrekt konfiguriert ist.`
      );
    } finally {
      setIsRequestingFeedback(false);
    }
  };

  /**
   * Check microphone permissions before starting
   */
  const checkMicrophonePermissions = async () => {
    console.log('üé§ [MIC_CHECK] Checking microphone permissions...');

    try {
      // Check if browser supports getUserMedia
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('Browser does not support microphone access');
      }

      // Request microphone permission
      console.log('üé§ [MIC_CHECK] Requesting microphone permission...');
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      console.log('üé§ [MIC_CHECK] ‚úÖ Microphone permission granted');
      console.log('   Audio tracks:', stream.getAudioTracks().length);
      console.log('   Track settings:', stream.getAudioTracks()[0]?.getSettings());

      // Stop the test stream immediately
      stream.getTracks().forEach(track => {
        track.stop();
        console.log('üé§ [MIC_CHECK] Stopped test track:', track.label);
      });

      setMicrophoneError(null);
      return true;
    } catch (error) {
      console.error('üé§ [MIC_CHECK] ‚ùå Microphone access denied or failed:', {
        error,
        errorName: error?.name,
        errorMessage: error?.message
      });

      setMicrophoneError(error.message);
      return false;
    }
  };

  /**
   * Start the conversation
   */
  const handleStartConversation = async () => {
    console.log('üöÄ [START] Beginning conversation start sequence...');
    console.log(`   Agent ID: ${ELEVENLABS_AGENT_ID}`);
    console.log(`   Current status: ${conversation.status}`);

    if (!ELEVENLABS_AGENT_ID) {
      console.error('‚ùå [START] Agent ID is missing');
      return;
    }

    // Prevent multiple simultaneous connection attempts
    if (isStartingSession.current || conversation.status === 'connected' || conversation.status === 'connecting') {
      console.log('‚ö†Ô∏è [START] Session already starting or connected, skipping...');
      console.log(`   isStartingSession: ${isStartingSession.current}`);
      console.log(`   conversation.status: ${conversation.status}`);
      return;
    }

    try {
      // First, check microphone permissions
      console.log('üé§ [START] Step 1: Checking microphone permissions...');
      const hasMicPermission = await checkMicrophonePermissions();

      if (!hasMicPermission) {
        console.error('‚ùå [START] Cannot start without microphone permission');
        alert('Mikrofon-Zugriff erforderlich! Bitte erlaube den Zugriff auf dein Mikrofon, um das Gespr√§ch zu starten.');
        return;
      }

      isStartingSession.current = true;
      connectionTimestamp.current = Date.now();
      setConversationMessages([]); // Clear previous messages
      setMicrophoneError(null);

      // Start audio recording BEFORE ElevenLabs session to improve chances of microphone access
      console.log('üöÄ [START] Step 2: Starting audio recording for analysis...');
      await startAudioRecording();

      console.log('üöÄ [START] Step 3: Initiating ElevenLabs session...');
      console.log(`   Timestamp: ${new Date(connectionTimestamp.current).toISOString()}`);

      await conversation.startSession({
        agentId: ELEVENLABS_AGENT_ID,
        // Pass user data as client tools variables if needed
        clientTools: userData ? {
          user_name: userData.user_name,
          position: userData.position,
          company: userData.company
        } : {}
      });

      console.log('‚úÖ [START] Session start requested successfully');
    } catch (error) {
      console.error('‚ùå [START] Error starting conversation:', {
        error,
        errorName: error?.name,
        errorMessage: error?.message,
        errorStack: error?.stack
      });
      isStartingSession.current = false;

      // Show error to user
      alert(`Fehler beim Starten des Gespr√§chs: ${error.message}\n\nBitte √ºberpr√ºfe:\n- Mikrofon-Berechtigung\n- ElevenLabs Agent ID\n- Internetverbindung`);
    }
  };

  /**
   * Handles wizard completion
   */
  const handleWizardComplete = (data) => {
    console.log('üìù [WIZARD] User data collected:', data);
    setUserData(data);
    setShowWizard(false);

    // Store in localStorage for persistence
    localStorage.setItem('bewerbungstrainer_user_data', JSON.stringify(data));
  };

  // Check if user data exists in localStorage on mount
  useEffect(() => {
    const storedData = localStorage.getItem('bewerbungstrainer_user_data');
    if (storedData) {
      try {
        const parsed = JSON.parse(storedData);
        setUserData(parsed);
        setShowWizard(false);
      } catch (error) {
        console.error('Error parsing stored user data:', error);
      }
    }
  }, []);

  // Expose debug functions to window for testing
  useEffect(() => {
    window.debugGemini = {
      listModels: async () => {
        if (!GEMINI_API_KEY) {
          console.error('‚ùå GEMINI_API_KEY is not set');
          return;
        }
        try {
          const models = await listAvailableModels(GEMINI_API_KEY);
          console.log('Available Gemini models:', models);
          return models;
        } catch (error) {
          console.error('Error listing models:', error);
        }
      },
      testFeedback: async (transcript = 'Test transcript') => {
        if (!GEMINI_API_KEY) {
          console.error('‚ùå GEMINI_API_KEY is not set');
          return;
        }
        try {
          const feedback = await generateInterviewFeedback(transcript, GEMINI_API_KEY);
          console.log('Generated feedback:', feedback);
          return feedback;
        } catch (error) {
          console.error('Error generating feedback:', error);
        }
      },
      apiKey: GEMINI_API_KEY ? 'Set ‚úÖ' : 'Not set ‚ùå'
    };

    console.log(`
üîß Debug-Funktionen verf√ºgbar:
  - window.debugGemini.listModels() - Liste verf√ºgbare Gemini-Modelle
  - window.debugGemini.testFeedback() - Teste Feedback-Generierung
  - window.debugGemini.apiKey - Zeige API-Key Status
    `);

    return () => {
      delete window.debugGemini;
    };
  }, [GEMINI_API_KEY]);

  // Show wizard if user hasn't completed it yet
  if (showWizard) {
    return <UserWizard onComplete={handleWizardComplete} />;
  }

  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-50 to-blue-50 flex items-center justify-center p-4">
      <div className="w-full max-w-4xl">
        {/* Main Card */}
        <div className="bg-white rounded-lg shadow-2xl overflow-hidden">
          {/* Header */}
          <Header />

          {/* Main Content Area */}
          <div className="p-6 space-y-6">
            {/* User Profile Info */}
            {userData && (
              <div className="bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200 rounded-lg p-4">
                <div className="flex items-center justify-between">
                  <div className="flex-1">
                    <h3 className="text-sm font-semibold text-green-900 mb-2">Dein Profil</h3>
                    <div className="grid grid-cols-3 gap-4 text-sm">
                      <div>
                        <span className="text-green-700 font-medium">Name:</span>
                        <p className="text-green-900">{userData.user_name}</p>
                      </div>
                      <div>
                        <span className="text-green-700 font-medium">Position:</span>
                        <p className="text-green-900">{userData.position}</p>
                      </div>
                      <div>
                        <span className="text-green-700 font-medium">Unternehmen:</span>
                        <p className="text-green-900">{userData.company}</p>
                      </div>
                    </div>
                  </div>
                  <Button
                    onClick={() => {
                      if (confirm('M√∂chtest du deine Profildaten wirklich √§ndern? Das aktuelle Gespr√§ch wird beendet.')) {
                        localStorage.removeItem('bewerbungstrainer_user_data');
                        setUserData(null);
                        setShowWizard(true);
                        if (conversation.status === 'connected') {
                          conversation.endSession();
                        }
                      }
                    }}
                    variant="outline"
                    size="sm"
                    className="ml-4"
                  >
                    Bearbeiten
                  </Button>
                </div>
              </div>
            )}

            {/* Instructions */}
            <div className="bg-blue-50 border border-blue-200 rounded-lg p-4">
              <div className="flex items-start gap-3">
                <MessageSquare className="w-5 h-5 text-blue-600 flex-shrink-0 mt-0.5" />
                <div className="text-sm text-blue-900">
                  <p className="font-semibold mb-1">Willkommen zum Bewerbungsgespr√§ch!</p>
                  <p className="text-blue-700">
                    Klicke auf "Gespr√§ch starten", um mit Herrn M√ºller zu sprechen.
                    Antworte nat√ºrlich und ehrlich auf die Fragen.
                    Am Ende erh√§ltst du ein detailliertes Feedback zu deiner Performance.
                  </p>
                </div>
              </div>
            </div>

            {/* ElevenLabs Conversation Interface */}
            <div className="bg-slate-50 rounded-lg p-6 min-h-[400px] border-2 border-slate-200">
              {ELEVENLABS_AGENT_ID ? (
                <div className="flex flex-col items-center justify-center h-full space-y-6">
                  {/* Status Display */}
                  <div className="text-center">
                    <div className="inline-flex items-center gap-2 px-4 py-2 bg-white rounded-full shadow-sm border">
                      <div className={`w-3 h-3 rounded-full ${
                        conversation.status === 'connected' ? 'bg-green-500 animate-pulse' :
                        conversation.status === 'connecting' ? 'bg-yellow-500 animate-pulse' :
                        'bg-slate-300'
                      }`} />
                      <span className="text-sm font-medium">
                        {conversation.status === 'connected' ? 'Verbunden' :
                         conversation.status === 'connecting' ? 'Verbinde...' :
                         'Getrennt'}
                      </span>
                    </div>
                  </div>

                  {/* Conversation Controls */}
                  {conversation.status !== 'connected' ? (
                    <div className="text-center space-y-4">
                      <Phone className="w-16 h-16 text-blue-600 mx-auto" />
                      <div>
                        <h3 className="text-lg font-semibold text-slate-700 mb-2">
                          Bereit f√ºr dein Bewerbungsgespr√§ch?
                        </h3>
                        <p className="text-sm text-slate-600 mb-4">
                          Klicke auf "Gespr√§ch starten", um mit Herrn M√ºller zu sprechen
                        </p>
                        <Button
                          onClick={handleStartConversation}
                          size="lg"
                          className="bg-green-600 hover:bg-green-700"
                          disabled={conversation.status === 'connecting' || isStartingSession.current}
                        >
                          <Phone className="w-4 h-4 mr-2" />
                          {conversation.status === 'connecting' ? 'Verbinde...' : 'Gespr√§ch starten'}
                        </Button>
                      </div>
                    </div>
                  ) : (
                    <div className="text-center space-y-6 w-full">
                      {/* Speaking Indicator */}
                      <div className="flex flex-col items-center">
                        {conversation.isSpeaking && (
                          <div className="mb-4">
                            <div className="flex gap-1 items-end h-12">
                              {[...Array(5)].map((_, i) => (
                                <div
                                  key={i}
                                  className="w-2 bg-blue-600 rounded-full animate-pulse"
                                  style={{
                                    height: `${Math.random() * 100}%`,
                                    animationDelay: `${i * 0.1}s`,
                                  }}
                                />
                              ))}
                            </div>
                            <p className="text-sm text-slate-600 mt-2">
                              {conversation.isSpeaking ? 'Herr M√ºller spricht...' : 'Du bist dran'}
                            </p>
                          </div>
                        )}

                        {/* Microphone Visual */}
                        <div className={`w-24 h-24 rounded-full flex items-center justify-center ${
                          conversation.micMuted ? 'bg-red-100' : 'bg-blue-100'
                        }`}>
                          {conversation.micMuted ? (
                            <MicOff className="w-12 h-12 text-red-600" />
                          ) : (
                            <Mic className="w-12 h-12 text-blue-600" />
                          )}
                        </div>

                        <p className="text-xs text-slate-500 mt-2">
                          {conversation.micMuted ? 'Mikrofon aus' : 'Spreche klar und deutlich'}
                        </p>
                      </div>

                      {/* Message Log */}
                      {conversationMessages.length > 0 && (
                        <div className="max-h-40 overflow-y-auto space-y-2 text-left bg-white p-4 rounded-lg">
                          {conversationMessages.slice(-3).map((msg, idx) => (
                            <div key={idx} className={`text-sm ${
                              msg.source === 'ai' ? 'text-blue-700' : 'text-slate-700'
                            }`}>
                              <span className="font-semibold">
                                {msg.source === 'ai' ? 'Herr M√ºller' : 'Du'}:
                              </span>{' '}
                              {msg.message}
                            </div>
                          ))}
                        </div>
                      )}

                      {/* End Call Button */}
                      <Button
                        onClick={handleEndInterview}
                        disabled={isRequestingFeedback}
                        variant="destructive"
                        size="lg"
                      >
                        <PhoneOff className="w-4 h-4 mr-2" />
                        Gespr√§ch beenden & Feedback erhalten
                      </Button>
                    </div>
                  )}
                </div>
              ) : (
                <div className="flex flex-col items-center justify-center h-full text-center py-12">
                  <StopCircle className="w-16 h-16 text-red-500 mb-4" />
                  <h3 className="text-lg font-semibold text-slate-700 mb-2">
                    ElevenLabs Agent ID fehlt
                  </h3>
                  <p className="text-sm text-slate-600 max-w-md">
                    Bitte setze die <code className="bg-slate-200 px-2 py-1 rounded">VITE_ELEVENLABS_AGENT_ID</code>
                    {' '}in der .env Datei, um das Interview zu starten.
                  </p>
                </div>
              )}
            </div>

            {/* Warning if microphone error occurred */}
            {microphoneError && (
              <div className="bg-red-50 border border-red-200 rounded-lg p-4">
                <p className="text-sm text-red-800">
                  <span className="font-semibold">Mikrofon-Fehler:</span> {microphoneError}
                  <br />
                  <span className="text-xs mt-1 block">
                    Bitte stelle sicher, dass dein Browser Zugriff auf das Mikrofon hat.
                    √úberpr√ºfe die Browser-Einstellungen und erlaube den Mikrofonzugriff f√ºr diese Seite.
                  </span>
                </p>
              </div>
            )}

            {/* Warning if Gemini API key is missing */}
            {!GEMINI_API_KEY && (
              <div className="bg-yellow-50 border border-yellow-200 rounded-lg p-4">
                <p className="text-sm text-yellow-800">
                  <span className="font-semibold">Hinweis:</span> Der Gemini API Key ist nicht konfiguriert.
                  Feedback-Funktion ist nicht verf√ºgbar.
                </p>
              </div>
            )}
          </div>
        </div>

        {/* Footer */}
        <div className="mt-6 text-center text-sm text-slate-600">
          <p>Bewerbungstrainer ¬© 2025 | Powered by ElevenLabs & Google Gemini</p>
        </div>
      </div>

      {/* Feedback Modal */}
      <FeedbackModal
        isOpen={showFeedbackModal}
        onClose={() => setShowFeedbackModal(false)}
        feedbackContent={feedbackContent}
        audioAnalysisContent={audioAnalysisContent}
        isLoading={isRequestingFeedback}
      />
    </div>
  );
}

export default App;
